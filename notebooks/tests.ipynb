{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Rank         Domain  Keywords in SERPs  \\\n",
      "0                         1   youtube.com\"       3.946606e+08   \n",
      "1                         2  facebook.com\"       3.085987e+08   \n",
      "2          3,wikipedia.org\"      252339137       2.966584e+10   \n",
      "3          4,instagram.com\"      200435287       8.630533e+09   \n",
      "4             5,reddit.com\"      199049683       3.409909e+09   \n",
      "..                      ...            ...                ...   \n",
      "995            996,fao.org\"        2210191       1.693894e+07   \n",
      "996    997,sueddeutsche.de\"        2209516       1.135997e+07   \n",
      "997  998,allcitycanvas.com\"        2205456       4.015313e+06   \n",
      "998         999,nasdaq.com\"        2205230       6.688247e+07   \n",
      "999      1000,brunch.co.kr\"        2200759       1.166616e+07   \n",
      "\n",
      "     Estimated organic traffic  \n",
      "0                 1.244089e+10  \n",
      "1                 7.554383e+09  \n",
      "2                          NaN  \n",
      "3                          NaN  \n",
      "4                          NaN  \n",
      "..                         ...  \n",
      "995                        NaN  \n",
      "996                        NaN  \n",
      "997                        NaN  \n",
      "998                        NaN  \n",
      "999                        NaN  \n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV como texto\n",
    "with open('../server/datasets/TOP_Ranked_Websites_DataSet.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Procesar cada l√≠nea para eliminar comillas innecesarias\n",
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    cleaned_line = line.replace('\"\"', '')  # Reemplazar las comillas dobles por una sola\n",
    "    cleaned_lines.append(cleaned_line)\n",
    "\n",
    "# Guardar el archivo limpio\n",
    "with open('../server/datasets/TOP_Ranked_Websites_DataSet.csv', 'w') as file:\n",
    "    file.writelines(cleaned_lines)\n",
    "\n",
    "# Leer con pandas\n",
    "df = pd.read_csv('../server/datasets/TOP_Ranked_Websites_DataSet.csv')\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
